#include "e8.hpp"

#include <iostream>
#include "raylib.h"
#include <cnpy.h>

#include "../macos/vsync_timer.hpp"

#include "../s3/cam.hpp"
#include "../s3/window.hpp"
#include "../s4/utils.hpp"
#include "../s3/Serial.hpp"
#include "shared.hpp"
#include <OpenGL/gl.h>
#include <chrono>
#include <future>
#include <thread>


struct IndexData {
    int64_t actual;
    int64_t expected;

    IndexData (int64_t x, int64_t y) :
    actual(x), expected(y) {}

    IndexData () : actual(0), expected(0) {}
};

std::vector<Texture> e9_GenerateSynchronizationTextures (const int64_t n_bits);

template<typename T>
int64_t             e9_argmin(const std::vector<T>&); 

int e9 () {
    Pylon::PylonAutoInitTerm init {};

    /* Initialize screen */
    s3_Window window {};
    window.Height  = 1600;
    window.Width   = 2560;
    window.wmode   = BORDERLESS;
    window.fmode   = NO_TARGET_FPS;
    //window.fps     = 60;
    window.monitor = 1;
    window.load();

    /* Serial connection */
    /* Serial is used to trigger the FPGA board to allow
       synchronization between camera and DLP/PLM */
    Serial serial {"/dev/tty.usbmodem8326898B1E1E1", 115200};
    serial.Open();

    std::atomic<int64_t> captures_pending {0};

    std::atomic<bool> enable_capture {false};
    std::vector<int64_t> vsync_time_stamps;
    std::vector<int64_t> capture_time_stamps;
    std::function<void()> timer = [&captures_pending,&serial,&vsync_time_stamps,&capture_time_stamps,&enable_capture]() {
        auto now = std::chrono::high_resolution_clock::now();
        int64_t us = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch()).count();
        vsync_time_stamps.push_back(us);
        if (enable_capture.load()) {
            captures_pending.fetch_add(1,std::memory_order_release);
            capture_time_stamps.push_back(us);
            serial.Signal();
            enable_capture.store(false,std::memory_order_release);
        }
    };

    /* Create timers */
    macOS_Vsync_Timer mvt {window.monitor, timer};

    /* Create Camera */
    s3_Camera_Properties cam_properties;
    cam_properties.AcqFrameRate = 1800;
    cam_properties.Height       = 320;
    cam_properties.Width        = 240;

    s3_Camera camera {cam_properties};
    camera.open();

    const int64_t n_bits = 24;
    int64_t frame_counter = 0;
    int64_t image_counter = 0;
    auto textures = e9_GenerateSynchronizationTextures(n_bits);
    int64_t previous_first_capture_time = 0;

    camera.start();
    std::vector<int16_t> is;
    std::vector<int16_t> ts;
    std::vector<int16_t> diffs;

    std::atomic<bool> end_thread {false};
    std::atomic<bool> started {false};
    std::atomic<IndexData> indexData;
    std::atomic<int64_t> cdiffs {0};
    std::atomic<int64_t> ic_p {0};
    std::atomic<int64_t> tdiffs {0};
    std::function<void()> capture_function = [&ic_p, &started, &captures_pending,&ts, &is, &end_thread, &camera, &n_bits, &indexData, &mvt, &cdiffs, &tdiffs](){
        int64_t i_c = 0;
        int64_t vs_1 = mvt.vsync_counter.load();

        auto now = std::chrono::high_resolution_clock::now();
        int64_t us_1 = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch()).count();
        while (!end_thread) {
            int64_t image_count = 0;
            int64_t m = INT64_MIN;
            int64_t m_i = 0;
            if (captures_pending.load() <= 0) continue;
            while(image_count<n_bits) {
                torch::Tensor image = camera.sread();
                auto sum = image.sum().item<int64_t>();

                if (sum > m) {
                    m_i = image_count;
                    m   = sum;
                }
                ++image_count;
            }
            is.push_back(m_i);

            started.store(true);
            indexData.store(IndexData(m_i, ts[i_c]), std::memory_order_release);
            ic_p.store(i_c);
            ++i_c;
            int64_t vs_2 = mvt.vsync_counter.load();
            auto d = vs_2 - vs_1;
            cdiffs.store(d);
            vs_1 = vs_2;
            captures_pending.fetch_sub(1,std::memory_order_release);
            now = std::chrono::high_resolution_clock::now();
            int64_t us_2 = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch()).count();
            tdiffs.store(us_2 - us_1);
            us_1 = us_2;
        }
    };
    std::thread capture_thread {capture_function};

    int64_t vs_c = mvt.vsync_counter.load();
    int64_t breakpoint_countdown = 10;
    bool    same_error_det = false;
    bool    one_behind_error_det = false;
    std::string notice_1 = "", notice_2 = "", notice_3 = "", notice_4 = "";
    int64_t break_counter = 10;

    auto now = std::chrono::high_resolution_clock::now();
    int64_t us_1 = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch()).count();

    while (!WindowShouldClose()) {
        auto &texture = textures[frame_counter % n_bits];

        /* Draw loop */
        BeginDrawing();
        ClearBackground(BLACK);
        DrawTexturePro(
            texture,
            {0, 0, 1, 1}, // Source rectangle (1x1 texture)
            {0, 0, (float)window.Width, (float)window.Height}, // Destination rectangle (full screen)
            {0, 0}, 0.0f, WHITE
        );
        EndDrawing();
        
        while (enable_capture.load());
        enable_capture.store(true,std::memory_order_release);
        
        int64_t vs_c_1 = mvt.vsync_counter.load();
        int64_t vs_diff = vs_c_1 - vs_c;

        ts.push_back(frame_counter % n_bits);
        diffs.push_back(vs_c_1 - vs_c);

        IndexData idd = indexData.load();
        int64_t al = idd.actual, el = idd.expected;
        int64_t wel = (((el-1) % 24) + 24) % 24;

        bool same_det = al == el;
        bool one_behind_det = al == wel;

        if (!same_det && !same_error_det) {
            same_error_det = true;
            notice_1 = std::string("*")+std::to_string(frame_counter);
        }

        if (same_error_det && !one_behind_det && !one_behind_error_det) {
            one_behind_error_det = true;
            notice_2 = std::string("*")+std::to_string(frame_counter);
        }

        if (notice_3 == "" && started.load()) {
            notice_3 = std::string("*")+std::to_string(frame_counter);
        }

        int64_t cd = cdiffs.load();
        if (cd == 2) {
            notice_4 = std::string("*")+std::to_string(frame_counter);
        }

        now = std::chrono::high_resolution_clock::now();
        int64_t us_2 = std::chrono::duration_cast<std::chrono::microseconds>(now.time_since_epoch()).count();
        auto ft = us_2 - us_1;
        us_1 = us_2;

        std::cout<<"1-------------------------------------------------------------\n";
        std::cout<<"INFO: [e9] FrameTime: "<<ft<<" us\n";
        std::cout<<"INFO: [e9] Actual: "<<al<<'\n';
        std::cout<<"INFO: [e9] Expected: "<<el<<'\n';
        std::cout<<"INFO: [e9] Current: " << (frame_counter % n_bits) << '\n';
        std::cout<<"INFO: [e9] VSYNC Differences: "<<(vs_c_1 - vs_c) <<'\n';
        std::cout<<"INFO: [e9] Capture VSYNC: "<<cd<<" "<<notice_4<<'\n';
        std::cout<<"INFO: [e9] Capture Time: "<<tdiffs.load()<<'\n';
        std::cout<<"INFO: [e9] Captures inflight: "<<captures_pending.load()<<'\n';
        std::cout<<"INFO: [e9] Image Index: "<<ic_p.load()<<'\n';
        std::cout<<"INFO: [e9] Same: "<<(al==el)<<" "<<notice_1<<'\n';
        std::cout<<"INFO: [e9] One Behind: "<<(al==wel)<<" "<<notice_2<<'\n';
        std::cout<<"INFO: [e9] Frame Index: "<<frame_counter<<" "<<notice_3<<'\n';
        std::cout<<"2-------------------------------------------------------------\n";

        if (one_behind_error_det) {
            --break_counter;
            if (break_counter <= 0)
                break;
        }

        vs_c = vs_c_1;
        ++frame_counter;
    }

    while (captures_pending.load() > 0);

    end_thread.store(true);
    capture_thread.join();

    camera.close();
    serial.Close();

    // save to numpy
    cnpy::npy_save("TimingData/1_signal.npy", is.data(), {is.size()}, "w");
    cnpy::npy_save("TimingData/1_bits.npy", ts.data(), {ts.size()}, "w");
    cnpy::npy_save("TimingData/1_vs.npy", diffs.data(), {diffs.size()}, "w");
    cnpy::npy_save("TimingData/1_capture.npy", capture_time_stamps.data(), {capture_time_stamps.size()}, "w");
    

    for (auto &t : textures)
        UnloadTexture(t);

    window.close(); /* close window */

    return 0;
}

std::vector<Texture> e9_GenerateSynchronizationTextures(const int64_t n_bits) {
    std::vector<Texture> textures;
    textures.reserve(n_bits);

    for (int64_t i = 0; i < n_bits; ++i) {
        unsigned char pixel[3] = {0, 0, 0};
        int byte_index = i / 8;
        int bit_index  = i % 8;
        pixel[byte_index] = 1 << bit_index;

        for (int j = 0; j < 3; ++j)
            pixel[j] = ~pixel[j];

        Image image = {
            .data = pixel,
            .width = 1,
            .height = 1,
            .mipmaps = 1,
            .format = PIXELFORMAT_UNCOMPRESSED_R8G8B8
        };

        Texture tex = LoadTextureFromImage(image);
        SetTextureFilter(tex, TEXTURE_FILTER_POINT); // Use nearest neighbor
        textures.push_back(tex);
    }

    return textures;
}

template<typename T>
int64_t e9_argmin(const std::vector<T> &v) {
    int64_t m = INT64_MAX;
    int64_t j = 0;

    for (int i = 0; i < v.size(); ++i) {
        if (v[i] < m) {
            j = i;
            m = v[i];
        }
    }

    return j;    /* return index */
}